{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3594e220",
   "metadata": {},
   "source": [
    "### Labrador Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8438363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.preprocessing import preprocess_df, TextEncoder, set_labels_features\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.labrador import Labrador\n",
    "from src.tokenizers import LabradorTokenizer\n",
    "from src.dataset import LabradorDataset\n",
    "\n",
    "from src.train import train_labrador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839103a9",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c6e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset:\n",
    "FILE = 'data/morning_lab_values.csv'\n",
    "COLUMNS = ['Bic', 'Crt', 'Pot', 'Sod', 'Ure', 'Hgb', 'Plt', 'Wbc']\n",
    "\n",
    "# Device:\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('mps') if torch.cuda.is_available() else torch.device('cpu') # Apple Silicon\n",
    "\n",
    "# Data loader: \n",
    "test_size = 0.2\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "max_len = 10\n",
    "MASKING = 0.20\n",
    "\n",
    "# Model:\n",
    "embedding_dim = 756\n",
    "hidden_dim = 756\n",
    "transformer_heads = 12\n",
    "num_blocks = 12\n",
    "transformer_feedforward_dim = 3072\n",
    "dropout_rate = 0.3\n",
    "continuous_head_activation = 'relu'\n",
    "\n",
    "# Training:\n",
    "optimizer = 'Adam'\n",
    "num_epochs = 2\n",
    "save_model = True\n",
    "model_path = 'labrador_model.pth'\n",
    "categorical_loss_weight = 1.0\n",
    "continuous_loss_weight = 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42aeb9",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ea9b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>charthour</th>\n",
       "      <th>storetime</th>\n",
       "      <th>storehour</th>\n",
       "      <th>chartday</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10312413</td>\n",
       "      <td>51222</td>\n",
       "      <td>2173-06-05 08:20:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2173-06-05 08:47:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2173-06-05</td>\n",
       "      <td>12.8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25669789.0</td>\n",
       "      <td>10390828</td>\n",
       "      <td>51222</td>\n",
       "      <td>2181-10-26 07:55:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2181-10-26 08:46:00</td>\n",
       "      <td>8</td>\n",
       "      <td>2181-10-26</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26646522.0</td>\n",
       "      <td>10447634</td>\n",
       "      <td>51222</td>\n",
       "      <td>2165-03-07 06:55:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2165-03-07 07:23:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2165-03-07</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27308928.0</td>\n",
       "      <td>10784877</td>\n",
       "      <td>51222</td>\n",
       "      <td>2170-05-11 06:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2170-05-11 06:43:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2170-05-11</td>\n",
       "      <td>10.3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28740988.0</td>\n",
       "      <td>11298819</td>\n",
       "      <td>51222</td>\n",
       "      <td>2142-09-13 07:15:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2142-09-13 09:23:00</td>\n",
       "      <td>9</td>\n",
       "      <td>2142-09-13</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  subject_id  itemid            charttime  charthour  \\\n",
       "0         NaN    10312413   51222  2173-06-05 08:20:00          8   \n",
       "1  25669789.0    10390828   51222  2181-10-26 07:55:00          7   \n",
       "2  26646522.0    10447634   51222  2165-03-07 06:55:00          6   \n",
       "3  27308928.0    10784877   51222  2170-05-11 06:00:00          6   \n",
       "4  28740988.0    11298819   51222  2142-09-13 07:15:00          7   \n",
       "\n",
       "             storetime  storehour    chartday  valuenum  cnt  \n",
       "0  2173-06-05 08:47:00          8  2173-06-05      12.8    8  \n",
       "1  2181-10-26 08:46:00          8  2181-10-26       9.4    8  \n",
       "2  2165-03-07 07:23:00          7  2165-03-07      11.1    8  \n",
       "3  2170-05-11 06:43:00          6  2170-05-11      10.3    8  \n",
       "4  2142-09-13 09:23:00          9  2142-09-13      10.2    8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(FILE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252ee2df",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "436ec03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler by default\n",
    "mrl = preprocess_df(df, columns_to_scale=COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad4f82",
   "metadata": {},
   "source": [
    "### Generate Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79463800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the sequences:\n",
    "text_encoder = TextEncoder(Repetition_id=True, labs_as_num=True, return_lists=True)\n",
    "mrl, grouped_mrl = text_encoder.encode_text(mrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce194bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>itemid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>chartday</th>\n",
       "      <th>Bic</th>\n",
       "      <th>Crt</th>\n",
       "      <th>Pot</th>\n",
       "      <th>Sod</th>\n",
       "      <th>Ure</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>Plt</th>\n",
       "      <th>Wbc</th>\n",
       "      <th>nstr</th>\n",
       "      <th>lab_ids</th>\n",
       "      <th>lab_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853.0</td>\n",
       "      <td>2180-05-07</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.088028</td>\n",
       "      <td>0.585253</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>Bic 0.5306122448979591 Crt 0.00789473684210526...</td>\n",
       "      <td>[Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]</td>\n",
       "      <td>[0.5306122448979591, 0.007894736842105262, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22841357.0</td>\n",
       "      <td>2180-06-27</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>Bic 0.46938775510204084 Crt 0.0078947368421052...</td>\n",
       "      <td>[Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]</td>\n",
       "      <td>[0.46938775510204084, 0.007894736842105262, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>25742920.0</td>\n",
       "      <td>2180-08-06</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>0.130282</td>\n",
       "      <td>0.557604</td>\n",
       "      <td>0.053782</td>\n",
       "      <td>0.008539</td>\n",
       "      <td>Bic 0.48979591836734687 Crt 0.0157894736842105...</td>\n",
       "      <td>[Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]</td>\n",
       "      <td>[0.48979591836734687, 0.015789473684210523, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "itemid  subject_id     hadm_id    chartday       Bic       Crt       Pot  \\\n",
       "0         10000032  22595853.0  2180-05-07  0.530612  0.007895  0.258621   \n",
       "1         10000032  22841357.0  2180-06-27  0.469388  0.007895  0.318966   \n",
       "2         10000032  25742920.0  2180-08-06  0.489796  0.015789  0.413793   \n",
       "\n",
       "itemid       Sod       Ure       Hgb       Plt       Wbc  \\\n",
       "0       0.609524  0.088028  0.585253  0.027731  0.004782   \n",
       "1       0.504762  0.102113  0.571429  0.055462  0.007515   \n",
       "2       0.504762  0.130282  0.557604  0.053782  0.008539   \n",
       "\n",
       "itemid                                               nstr  \\\n",
       "0       Bic 0.5306122448979591 Crt 0.00789473684210526...   \n",
       "1       Bic 0.46938775510204084 Crt 0.0078947368421052...   \n",
       "2       Bic 0.48979591836734687 Crt 0.0157894736842105...   \n",
       "\n",
       "itemid                                   lab_ids  \\\n",
       "0       [Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]   \n",
       "1       [Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]   \n",
       "2       [Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]   \n",
       "\n",
       "itemid                                         lab_values  \n",
       "0       [0.5306122448979591, 0.007894736842105262, 0.2...  \n",
       "1       [0.46938775510204084, 0.007894736842105262, 0....  \n",
       "2       [0.48979591836734687, 0.015789473684210523, 0....  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrl.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf927d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>nstr</th>\n",
       "      <th>lab_ids</th>\n",
       "      <th>lab_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000019.0</td>\n",
       "      <td>[Bic 0.4489795918367347 Crt 0.0289473684210526...</td>\n",
       "      <td>[Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]</td>\n",
       "      <td>[0.4489795918367347, 0.02894736842105263, 0.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000024.0</td>\n",
       "      <td>[Bic 0.46938775510204084 Crt 0.028947368421052...</td>\n",
       "      <td>[Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]</td>\n",
       "      <td>[0.46938775510204084, 0.02894736842105263, 0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000034.0</td>\n",
       "      <td>[Bic 0.4489795918367347 Crt 0.0605263157894736...</td>\n",
       "      <td>[Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]</td>\n",
       "      <td>[0.4489795918367347, 0.06052631578947368, 0.28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id                                               nstr  \\\n",
       "0  20000019.0  [Bic 0.4489795918367347 Crt 0.0289473684210526...   \n",
       "1  20000024.0  [Bic 0.46938775510204084 Crt 0.028947368421052...   \n",
       "2  20000034.0  [Bic 0.4489795918367347 Crt 0.0605263157894736...   \n",
       "\n",
       "                                    lab_ids  \\\n",
       "0  [Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]   \n",
       "1  [Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]   \n",
       "2  [Bic, Crt, Pot, Sod, Ure, Hgb, Plt, Wbc]   \n",
       "\n",
       "                                          lab_values  \n",
       "0  [0.4489795918367347, 0.02894736842105263, 0.17...  \n",
       "1  [0.46938775510204084, 0.02894736842105263, 0.3...  \n",
       "2  [0.4489795918367347, 0.06052631578947368, 0.28...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the largest element in: \n",
    "grouped_mrl.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92fa35",
   "metadata": {},
   "source": [
    "#### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_ids = grouped_mrl.lab_ids.values\n",
    "lab_values = grouped_mrl.lab_values.values\n",
    "\n",
    "lab_ids_train, lab_ids_test, lab_values_train, lab_values_test = train_test_split(lab_ids, lab_values, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42ae57",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LabradorTokenizer()\n",
    "# Get unique lab ids:\n",
    "unique_ids = set(np.concatenate(lab_ids_train))\n",
    "# train the tokenizer:\n",
    "tokenizer.train(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6ff1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([[ 2,  0,  7,  1,  3,  4,  5,  6, 10, 10],\n",
       "        [ 2,  0,  7,  1,  3,  4,  5,  6, 10, 10],\n",
       "        [ 2,  0,  7,  1,  3,  4,  5,  6, 10, 10],\n",
       "        [ 2,  0,  7,  1,  3,  4,  5,  6, 10, 10],\n",
       "        [ 2,  0,  7,  1,  3,  4,  5,  6, 10, 10]]),\n",
       " 'continuous': array([[6.73469388e-01, 7.89473684e-02, 1.46551724e-01, 6.09523810e-01,\n",
       "         3.80281690e-01, 6.31336406e-01, 4.15966387e-02, 6.94523511e-03,\n",
       "         1.00000000e+01, 1.00000000e+01],\n",
       "        [6.12244898e-01, 2.89473684e-02, 1.37931034e-01, 7.04761905e-01,\n",
       "         9.85915493e-02, 3.50230415e-01, 7.85714286e-02, 1.04747808e-02,\n",
       "         1.00000000e+01, 1.00000000e+01],\n",
       "        [5.30612245e-01, 2.10526316e-02, 2.06896552e-01, 6.28571429e-01,\n",
       "         5.63380282e-02, 4.42396313e-01, 1.18067227e-01, 1.04747808e-02,\n",
       "         1.00000000e+01, 1.00000000e+01],\n",
       "        [4.48979592e-01, 1.84210526e-02, 2.32758621e-01, 6.28571429e-01,\n",
       "         3.16901408e-02, 6.77419355e-01, 1.07983193e-01, 1.04747808e-02,\n",
       "         1.00000000e+01, 1.00000000e+01],\n",
       "        [4.48979592e-01, 4.47368421e-02, 3.10344828e-01, 6.00000000e-01,\n",
       "         1.40845070e-01, 5.11520737e-01, 1.05462185e-01, 2.25435500e-02,\n",
       "         1.00000000e+01, 1.00000000e+01]]),\n",
       " 'attention_mask': array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of how to use the tokenizer:\n",
    "tokenizer.tokenize_batch(lab_ids_train[:5], lab_values_train[:5], max_length=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7d54c",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fbb38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[MASK]': 8, '[NULL]': 9, '[PAD]': 10, 'Crt': 0, 'Sod': 1, 'Bic': 2, 'Ure': 3, 'Hgb': 4, 'Plt': 5, 'Wbc': 6, 'Pot': 7}\n",
      "{'[MASK]': 8, '[NULL]': 9, '[PAD]': 10, 'Crt': 0, 'Sod': 1, 'Bic': 2, 'Ure': 3, 'Hgb': 4, 'Plt': 5, 'Wbc': 6, 'Pot': 7}\n"
     ]
    }
   ],
   "source": [
    "dataset_train = LabradorDataset(continuous=lab_values_train, categorical=lab_ids_train, tokenizer=tokenizer, max_len=max_len, masking_prob=MASKING)\n",
    "dataset_test = LabradorDataset(continuous=lab_values_test, categorical=lab_ids_test, tokenizer=tokenizer, max_len=max_len, masking_prob=MASKING)\n",
    "\n",
    "# Dataloader:\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c9123",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ed51c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token = tokenizer.mask_token #-1\n",
    "null_token = tokenizer.null_token #-2\n",
    "pad_token = tokenizer.pad_token #-3\n",
    "vocab_size = tokenizer.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624cbd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Labrador(\n",
       "  (categorical_embedding_layer): Embedding(14, 756)\n",
       "  (continuous_embedding_layer): ContinuousEmbedding(\n",
       "    (special_token_embeddings): Embedding(3, 756)\n",
       "    (dense1): Linear(in_features=1, out_features=756, bias=True)\n",
       "    (dense2): Linear(in_features=756, out_features=756, bias=True)\n",
       "    (layernorm): LayerNorm((756,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (projection_layer): Linear(in_features=1512, out_features=756, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x TransformerBlock(\n",
       "      (att): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=756, out_features=756, bias=True)\n",
       "      )\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=756, out_features=3072, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=3072, out_features=756, bias=True)\n",
       "      )\n",
       "      (layernorm1): LayerNorm((756,), eps=1e-05, elementwise_affine=True)\n",
       "      (layernorm2): LayerNorm((756,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (head): MLMPredictionHead(\n",
       "    (dense_categorical): Linear(in_features=756, out_features=756, bias=True)\n",
       "    (categorical_head): Linear(in_features=756, out_features=11, bias=True)\n",
       "    (dense_continuous): Linear(in_features=767, out_features=767, bias=True)\n",
       "    (continuous_head): Linear(in_features=767, out_features=1, bias=True)\n",
       "    (continuous_head_activation): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Labrador(mask_token=mask_token, pad_token=pad_token, null_token=null_token, vocab_size=vocab_size, embedding_dim=embedding_dim, transformer_heads=transformer_heads, num_blocks=num_blocks, transformer_feedforward_dim=transformer_feedforward_dim, include_head=True, continuous_head_activation=continuous_head_activation, dropout_rate=dropout_rate)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd4089",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145b5fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "categorical_loss_fn = nn.CrossEntropyLoss()\n",
    "continuous_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1eacdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3308 [00:00<22:40,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0674, 0.0647, 0.0985,  ..., 0.0599, 0.1077, 0.1267],\n",
      "         [0.0658, 0.0559, 0.0849,  ..., 0.0861, 0.0947, 0.1106],\n",
      "         [0.0743, 0.0714, 0.0937,  ..., 0.0733, 0.0990, 0.1159],\n",
      "         ...,\n",
      "         [0.0699, 0.0752, 0.0907,  ..., 0.0611, 0.1016, 0.1097],\n",
      "         [0.0759, 0.0696, 0.0782,  ..., 0.0743, 0.1014, 0.1023],\n",
      "         [0.0728, 0.0561, 0.0918,  ..., 0.0661, 0.0980, 0.1088]],\n",
      "\n",
      "        [[0.0567, 0.0602, 0.0954,  ..., 0.0649, 0.0868, 0.1314],\n",
      "         [0.0796, 0.0656, 0.0858,  ..., 0.0834, 0.0957, 0.1009],\n",
      "         [0.0702, 0.0679, 0.1127,  ..., 0.0842, 0.0849, 0.1072],\n",
      "         ...,\n",
      "         [0.0760, 0.0590, 0.0786,  ..., 0.0893, 0.0764, 0.0976],\n",
      "         [0.0704, 0.0695, 0.0809,  ..., 0.0708, 0.0882, 0.1215],\n",
      "         [0.0808, 0.0641, 0.0803,  ..., 0.0757, 0.0802, 0.1162]],\n",
      "\n",
      "        [[0.0603, 0.0641, 0.1025,  ..., 0.0661, 0.1133, 0.1247],\n",
      "         [0.0680, 0.0702, 0.0878,  ..., 0.0783, 0.1028, 0.0907],\n",
      "         [0.0786, 0.0670, 0.0943,  ..., 0.0739, 0.0951, 0.1129],\n",
      "         ...,\n",
      "         [0.0919, 0.0608, 0.0988,  ..., 0.0840, 0.0900, 0.0816],\n",
      "         [0.0709, 0.0629, 0.0899,  ..., 0.0754, 0.0934, 0.1248],\n",
      "         [0.0764, 0.0701, 0.0936,  ..., 0.0665, 0.0774, 0.1141]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0696, 0.0707, 0.0817,  ..., 0.0707, 0.0964, 0.1132],\n",
      "         [0.0755, 0.0940, 0.0753,  ..., 0.0649, 0.1021, 0.0951],\n",
      "         [0.0736, 0.0883, 0.0973,  ..., 0.0773, 0.0948, 0.1036],\n",
      "         ...,\n",
      "         [0.0761, 0.0775, 0.0746,  ..., 0.0653, 0.0895, 0.1013],\n",
      "         [0.0744, 0.0623, 0.0814,  ..., 0.0761, 0.0915, 0.1192],\n",
      "         [0.0858, 0.0772, 0.0707,  ..., 0.0784, 0.0849, 0.1021]],\n",
      "\n",
      "        [[0.0714, 0.0668, 0.0950,  ..., 0.0670, 0.0967, 0.1251],\n",
      "         [0.0645, 0.0828, 0.0863,  ..., 0.0723, 0.0954, 0.0914],\n",
      "         [0.0723, 0.0731, 0.1088,  ..., 0.0688, 0.0934, 0.1065],\n",
      "         ...,\n",
      "         [0.0650, 0.0795, 0.0902,  ..., 0.0617, 0.1051, 0.0949],\n",
      "         [0.0736, 0.0686, 0.0724,  ..., 0.0769, 0.0833, 0.1183],\n",
      "         [0.0743, 0.0618, 0.0760,  ..., 0.0723, 0.0911, 0.1031]],\n",
      "\n",
      "        [[0.0623, 0.0694, 0.0982,  ..., 0.0703, 0.0963, 0.1519],\n",
      "         [0.0624, 0.0861, 0.0811,  ..., 0.0875, 0.1010, 0.0938],\n",
      "         [0.0702, 0.0611, 0.0830,  ..., 0.0868, 0.0843, 0.1044],\n",
      "         ...,\n",
      "         [0.0705, 0.0542, 0.0860,  ..., 0.0873, 0.0992, 0.0959],\n",
      "         [0.0700, 0.0726, 0.0759,  ..., 0.0777, 0.0948, 0.1170],\n",
      "         [0.0688, 0.0659, 0.0840,  ..., 0.0930, 0.0974, 0.1050]]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0498],\n",
      "         [0.0366]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0879],\n",
      "         [0.2001],\n",
      "         [0.0000],\n",
      "         [0.2293],\n",
      "         [0.1280]],\n",
      "\n",
      "        [[0.0668],\n",
      "         [0.0133],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0257],\n",
      "         [0.0580],\n",
      "         [0.0000],\n",
      "         [0.1453],\n",
      "         [0.0619]],\n",
      "\n",
      "        [[0.0041],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0087],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0729]],\n",
      "\n",
      "        [[0.1171],\n",
      "         [0.0380],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0879],\n",
      "         [0.1946],\n",
      "         [0.0000],\n",
      "         [0.0718],\n",
      "         [0.1825]],\n",
      "\n",
      "        [[0.0112],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1270],\n",
      "         [0.2638],\n",
      "         [0.0000],\n",
      "         [0.0892],\n",
      "         [0.1554]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0178],\n",
      "         [0.0000],\n",
      "         [0.1232],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0599],\n",
      "         [0.0000],\n",
      "         [0.0403],\n",
      "         [0.1370],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0258],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0196],\n",
      "         [0.1407]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0130],\n",
      "         [0.1546],\n",
      "         [0.1065]],\n",
      "\n",
      "        [[0.0151],\n",
      "         [0.1796],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0075],\n",
      "         [0.0000],\n",
      "         [0.0119],\n",
      "         [0.1432]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0925],\n",
      "         [0.0000],\n",
      "         [0.0462],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0128],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0251],\n",
      "         [0.1034]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0521],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1370],\n",
      "         [0.1250],\n",
      "         [0.0812],\n",
      "         [0.1435],\n",
      "         [0.0067]],\n",
      "\n",
      "        [[0.0118],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0433],\n",
      "         [0.0544],\n",
      "         [0.0045],\n",
      "         [0.1654],\n",
      "         [0.0280]],\n",
      "\n",
      "        [[0.0266],\n",
      "         [0.0039],\n",
      "         [0.0000],\n",
      "         [0.0311],\n",
      "         [0.0679],\n",
      "         [0.0008],\n",
      "         [0.1048],\n",
      "         [0.1712],\n",
      "         [0.2775],\n",
      "         [0.2931]],\n",
      "\n",
      "        [[0.0909],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0110],\n",
      "         [0.0347],\n",
      "         [0.0000],\n",
      "         [0.0928],\n",
      "         [0.1334]],\n",
      "\n",
      "        [[0.0228],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0596],\n",
      "         [0.0000],\n",
      "         [0.0082],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0639],\n",
      "         [0.0724],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0374],\n",
      "         [0.0539],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0228],\n",
      "         [0.0492]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0990],\n",
      "         [0.0047]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0620],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0026]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1404],\n",
      "         [0.0000],\n",
      "         [0.0480],\n",
      "         [0.0031]],\n",
      "\n",
      "        [[0.0374],\n",
      "         [0.0307],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1161],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1205]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0145],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0980]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1560],\n",
      "         [0.1330]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0653],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0798],\n",
      "         [0.0000],\n",
      "         [0.0704],\n",
      "         [0.0375]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0253],\n",
      "         [0.0000],\n",
      "         [0.0838],\n",
      "         [0.0299],\n",
      "         [0.1148],\n",
      "         [0.2205]],\n",
      "\n",
      "        [[0.1407],\n",
      "         [0.1903],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1889],\n",
      "         [0.0971],\n",
      "         [0.1432],\n",
      "         [0.1038]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0846]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0067],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0282],\n",
      "         [0.0000],\n",
      "         [0.0285],\n",
      "         [0.0796],\n",
      "         [0.0173]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0318],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0078],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0134],\n",
      "         [0.0000],\n",
      "         [0.0507],\n",
      "         [0.1348],\n",
      "         [0.1097],\n",
      "         [0.1796],\n",
      "         [0.2132]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0268],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0478],\n",
      "         [0.1134],\n",
      "         [0.0000],\n",
      "         [0.0546],\n",
      "         [0.0811],\n",
      "         [0.2123]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0774],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0025],\n",
      "         [0.0000],\n",
      "         [0.0879],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.1520],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0758],\n",
      "         [0.0399],\n",
      "         [0.0357],\n",
      "         [0.0297],\n",
      "         [0.1208]],\n",
      "\n",
      "        [[0.1473],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1389],\n",
      "         [0.1223]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.2480],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1110],\n",
      "         [0.0826],\n",
      "         [0.0063],\n",
      "         [0.0076],\n",
      "         [0.0438],\n",
      "         [0.1705]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0526],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1518],\n",
      "         [0.1589]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0390],\n",
      "         [0.0000],\n",
      "         [0.0870],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0142],\n",
      "         [0.0428]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0184],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1125],\n",
      "         [0.1522]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1140],\n",
      "         [0.0967],\n",
      "         [0.0507],\n",
      "         [0.0888]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0637],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0332],\n",
      "         [0.0000],\n",
      "         [0.0421],\n",
      "         [0.0217],\n",
      "         [0.0130],\n",
      "         [0.2388]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0158],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0087],\n",
      "         [0.0359],\n",
      "         [0.1451],\n",
      "         [0.0000],\n",
      "         [0.1081],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0011],\n",
      "         [0.0000],\n",
      "         [0.0235],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1659],\n",
      "         [0.0560],\n",
      "         [0.0871],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1390]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0313],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1082],\n",
      "         [0.0000],\n",
      "         [0.1526],\n",
      "         [0.1785]],\n",
      "\n",
      "        [[0.0065],\n",
      "         [0.1530],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0931],\n",
      "         [0.0000],\n",
      "         [0.0494],\n",
      "         [0.1028],\n",
      "         [0.1629],\n",
      "         [0.0425]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0851],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0166],\n",
      "         [0.0000],\n",
      "         [0.0154],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0355],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1484],\n",
      "         [0.0233],\n",
      "         [0.0000],\n",
      "         [0.1926],\n",
      "         [0.2243]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0044],\n",
      "         [0.0914]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0031],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0232],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0193],\n",
      "         [0.0079]],\n",
      "\n",
      "        [[0.0467],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0402]],\n",
      "\n",
      "        [[0.0790],\n",
      "         [0.1749],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0347],\n",
      "         [0.0000],\n",
      "         [0.0086],\n",
      "         [0.0703],\n",
      "         [0.2417]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0306],\n",
      "         [0.1134],\n",
      "         [0.0352]],\n",
      "\n",
      "        [[0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0705],\n",
      "         [0.0000]],\n",
      "\n",
      "        [[0.0195],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.0000],\n",
      "         [0.1333],\n",
      "         [0.1132]]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3308/3308 [04:14<00:00, 13.02it/s]\n",
      "  0%|          | 0/827 [00:00<?, ?it/s]/home/opc/anaconda3/envs/labrador/lib/python3.9/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._native_multi_head_attention(\n",
      "  1%|          | 6/827 [00:00<00:48, 16.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         ...,\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06]],\n",
      "\n",
      "        [[1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         ...,\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06]],\n",
      "\n",
      "        [[1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         ...,\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         ...,\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06]],\n",
      "\n",
      "        [[1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         ...,\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06]],\n",
      "\n",
      "        [[1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         ...,\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06],\n",
      "         [1.9272e-01, 1.0978e-01, 1.1388e-01,  ..., 1.1461e-06,\n",
      "          2.4443e-06, 1.5044e-06]]], device='cuda:0')\n",
      "tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 827/827 [00:18<00:00, 44.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Training Loss: 5.867214852982306, Validation Loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 79/3308 [00:06<04:25, 12.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train and validate the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_labrador\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_loss_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontinuous_loss_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 49\u001b[0m, in \u001b[0;36mtrain_labrador\u001b[0;34m(model, train_loader, val_loader, categorical_loss_fn, continuous_loss_fn, optimizer, num_epochs, device, save_model, model_path, continuous_loss_weight, categorical_loss_weight)\u001b[0m\n\u001b[1;32m     46\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     47\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 49\u001b[0m     total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     train_losses_per_iter\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     52\u001b[0m avg_train_loss \u001b[38;5;241m=\u001b[39m total_train_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train and validate the model\n",
    "trained_model = train_labrador(model, train_loader, test_loader, categorical_loss_fn, continuous_loss_fn, optimizer=optimizer, num_epochs=num_epochs, device=device, save_model=save_model, model_path=model_path, categorical_loss_weight=categorical_loss_weight, continuous_loss_weight=continuous_loss_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88031f0",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e682d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[MASK]': 8, '[NULL]': 9, '[PAD]': 10, 'Crt': 0, 'Sod': 1, 'Bic': 2, 'Ure': 3, 'Hgb': 4, 'Plt': 5, 'Wbc': 6, 'Pot': 7}\n"
     ]
    }
   ],
   "source": [
    "dataset_test = LabradorDataset(continuous=lab_values_test, categorical=lab_ids_test, tokenizer=tokenizer, max_len=max_len, masking_prob=0)\n",
    "# Dataloader:\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def test_model(model, test_loader, device, labs_list):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    metrics = {lab: {'rmse': [], 'mae': [], 'r2': []} for lab in labs_list}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for lab in labs_list:\n",
    "            print(f'Evaluating {lab}: ')\n",
    "            lab_token = test_loader.dataset.tokenizer.vocab[lab]\n",
    "\n",
    "            preds = []\n",
    "            true_vals = []\n",
    "            count = 0\n",
    "\n",
    "            for batch in tqdm(test_loader, leave=True):\n",
    "                lab_idx = (batch['input_ids'] == lab_token)\n",
    "                batch['continuous'][lab_idx] = torch.tensor(test_loader.dataset.tokenizer.mask_token, dtype=torch.float32, device=device)\n",
    "\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                continuous = batch['continuous'].to(device)\n",
    "                attn_mask = batch['attention_mask'].to(device)\n",
    "                labels_continuous = batch['labels_continuous'].to(device)\n",
    "                \n",
    "                if count == 0:\n",
    "                    #print(f'Input ids: {input_ids}')\n",
    "                    #print(f'Continuous: {continuous}')\n",
    "                    #print(f'Attn mask: {attn_mask}')\n",
    "                    #print(f'Labels continuous: {labels_continuous}')\n",
    "                    pass\n",
    "\n",
    "                outputs = model(input_ids, continuous, attn_mask=attn_mask)\n",
    "                continuous_output = outputs['continuous_output'].squeeze(-1)\n",
    "                if count == 0:\n",
    "                    #print(f'Continuous output: {continuous_output}')\n",
    "                    pass\n",
    "\n",
    "                masked_cont_indices = (continuous == test_loader.dataset.tokenizer.mask_token).to(device)\n",
    "                batch_preds = continuous_output[masked_cont_indices]\n",
    "                batch_labels = labels_continuous[masked_cont_indices].to(device)\n",
    "\n",
    "                preds.extend(batch_preds.tolist())\n",
    "                true_vals.extend(batch_labels.tolist())\n",
    "                \n",
    "                if count == 0:\n",
    "                    print(f'Preds: {batch_preds.tolist()}')\n",
    "                    print(f'True vals: {batch_labels.tolist()}')\n",
    "                    count += 1\n",
    "\n",
    "            rmse = np.sqrt(mean_squared_error(true_vals, preds))\n",
    "            mae = mean_absolute_error(true_vals, preds)\n",
    "            r2 = r2_score(true_vals, preds)\n",
    "\n",
    "            metrics[lab]['rmse'].append(rmse)\n",
    "            metrics[lab]['mae'].append(mae)\n",
    "            metrics[lab]['r2'].append(r2)\n",
    "\n",
    "            print(f'RMSE: {rmse:.3f}')\n",
    "            print(f'MAE: {mae:.3f}')\n",
    "            print(f'R2: {r2:.3f}')\n",
    "            print('-------------------')\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cb6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Bic: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/827 [00:00<00:49, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "True vals: [0.4285714328289032, 0.5306122303009033, 0.4897959232330322, 0.5102040767669678, 0.5714285969734192, 0.4693877696990967, 0.5102040767669678, 0.3877550959587097, 0.3469387888908386, 0.5102040767669678, 0.5306122303009033, 0.4897959232330322, 0.4285714328289032, 0.4285714328289032, 0.5510203838348389, 0.4285714328289032, 0.5102040767669678, 0.4693877696990967, 0.3877550959587097, 0.6326530575752258, 0.4285714328289032, 0.5510203838348389, 0.5102040767669678, 0.4897959232330322, 0.5918367505073547, 0.40816327929496765, 0.4693877696990967, 0.3469387888908386, 0.5306122303009033, 0.5102040767669678, 0.5306122303009033, 0.5918367505073547, 0.3877550959587097, 0.5306122303009033, 0.4897959232330322, 0.5306122303009033, 0.44897958636283875, 0.40816327929496765, 0.6326530575752258, 0.3877550959587097, 0.36734694242477417, 0.5306122303009033, 0.5102040767669678, 0.4897959232330322, 0.44897958636283875, 0.44897958636283875, 0.36734694242477417, 0.3877550959587097, 0.3877550959587097, 0.5306122303009033, 0.44897958636283875, 0.36734694242477417, 0.4897959232330322, 0.4285714328289032, 0.44897958636283875, 0.5510203838348389, 0.40816327929496765, 0.2857142984867096, 0.36734694242477417, 0.5102040767669678, 0.5918367505073547, 0.4897959232330322, 0.4285714328289032, 0.3877550959587097]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 287/827 [00:06<00:12, 42.75it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOLUMNS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 44\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, device, labs_list)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     43\u001b[0m masked_cont_indices \u001b[38;5;241m=\u001b[39m (continuous \u001b[38;5;241m==\u001b[39m test_loader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mmask_token)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 44\u001b[0m batch_preds \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuous_output\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmasked_cont_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m batch_labels \u001b[38;5;241m=\u001b[39m labels_continuous[masked_cont_indices]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     47\u001b[0m preds\u001b[38;5;241m.\u001b[39mextend(batch_preds\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_model(model, test_loader, device, COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed093933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labrador",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
