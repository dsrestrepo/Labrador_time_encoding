{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5TmEYvWCM0_",
        "outputId": "1c15c15e-1e92-4d2c-b03e-b3db4e60fff3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnlvrhwrabdS"
      },
      "source": [
        "### Big Query Integration:\n",
        "```\n",
        "%%bigquery morningroutinelab --project Cancer-Causal\n",
        "WITH cohort AS (\n",
        "  SELECT\n",
        "    hadm_id,\n",
        "    subject_id,\n",
        "    itemid,\n",
        "    charttime,\n",
        "    EXTRACT(HOUR FROM charttime) AS charthour,\n",
        "    storetime,\n",
        "    EXTRACT(HOUR FROM storetime) AS storehour,\n",
        "    EXTRACT(DATE FROM charttime) AS chartday,\n",
        "    valuenum\n",
        "  FROM\n",
        "    `physionet-data.mimiciv_hosp.labevents`\n",
        "  WHERE EXTRACT(HOUR FROM charttime) BETWEEN 5 AND 8\n",
        "    AND itemid IN (50912, 51265, 51222, 51301, 51006, 50983, 50882, 50971)\n",
        "),\n",
        "patdailycnt AS (\n",
        "  SELECT\n",
        "    subject_id,\n",
        "    chartday,\n",
        "    COUNT(DISTINCT itemid) AS cnt\n",
        "  FROM cohort where SAFE_CAST(valuenum AS FLOAT64) IS NOT NULL AND valuenum IS NOT NULL\n",
        "  GROUP BY subject_id, chartday\n",
        ")\n",
        "  SELECT cohort.*,patdailycnt.cnt\n",
        "  FROM cohort\n",
        "  RIGHT JOIN patdailycnt\n",
        "  ON cohort.subject_id = patdailycnt.subject_id AND cohort.chartday = patdailycnt.chartday\n",
        "  WHERE patdailycnt.cnt = 8\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKTdEz1XbInW",
        "outputId": "ed863b22-3947-4481-b608-e1d6bdc49f50"
      },
      "outputs": [],
      "source": [
        "### I'll read the dataset froma csv file\n",
        "#%cd '/content/drive/MyDrive/lab_values'\n",
        "FILE = 'morningroutinelab.csv'\n",
        "\n",
        "morningroutinelab = pd.read_csv(FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nr_W_-j_CQ5X",
        "outputId": "47867ebb-e016-4267-f021-0e6fea385ad6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>itemid</th>\n",
              "      <th>charttime</th>\n",
              "      <th>charthour</th>\n",
              "      <th>storetime</th>\n",
              "      <th>storehour</th>\n",
              "      <th>chartday</th>\n",
              "      <th>valuenum</th>\n",
              "      <th>cnt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>10312413</td>\n",
              "      <td>51222</td>\n",
              "      <td>2173-06-05 08:20:00</td>\n",
              "      <td>8</td>\n",
              "      <td>2173-06-05 08:47:00</td>\n",
              "      <td>8</td>\n",
              "      <td>2173-06-05</td>\n",
              "      <td>12.8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25669789.0</td>\n",
              "      <td>10390828</td>\n",
              "      <td>51222</td>\n",
              "      <td>2181-10-26 07:55:00</td>\n",
              "      <td>7</td>\n",
              "      <td>2181-10-26 08:46:00</td>\n",
              "      <td>8</td>\n",
              "      <td>2181-10-26</td>\n",
              "      <td>9.4</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26646522.0</td>\n",
              "      <td>10447634</td>\n",
              "      <td>51222</td>\n",
              "      <td>2165-03-07 06:55:00</td>\n",
              "      <td>6</td>\n",
              "      <td>2165-03-07 07:23:00</td>\n",
              "      <td>7</td>\n",
              "      <td>2165-03-07</td>\n",
              "      <td>11.1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27308928.0</td>\n",
              "      <td>10784877</td>\n",
              "      <td>51222</td>\n",
              "      <td>2170-05-11 06:00:00</td>\n",
              "      <td>6</td>\n",
              "      <td>2170-05-11 06:43:00</td>\n",
              "      <td>6</td>\n",
              "      <td>2170-05-11</td>\n",
              "      <td>10.3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28740988.0</td>\n",
              "      <td>11298819</td>\n",
              "      <td>51222</td>\n",
              "      <td>2142-09-13 07:15:00</td>\n",
              "      <td>7</td>\n",
              "      <td>2142-09-13 09:23:00</td>\n",
              "      <td>9</td>\n",
              "      <td>2142-09-13</td>\n",
              "      <td>10.2</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      hadm_id  subject_id  itemid            charttime  charthour  \\\n",
              "0         NaN    10312413   51222  2173-06-05 08:20:00          8   \n",
              "1  25669789.0    10390828   51222  2181-10-26 07:55:00          7   \n",
              "2  26646522.0    10447634   51222  2165-03-07 06:55:00          6   \n",
              "3  27308928.0    10784877   51222  2170-05-11 06:00:00          6   \n",
              "4  28740988.0    11298819   51222  2142-09-13 07:15:00          7   \n",
              "\n",
              "             storetime  storehour    chartday  valuenum  cnt  \n",
              "0  2173-06-05 08:47:00          8  2173-06-05      12.8    8  \n",
              "1  2181-10-26 08:46:00          8  2181-10-26       9.4    8  \n",
              "2  2165-03-07 07:23:00          7  2165-03-07      11.1    8  \n",
              "3  2170-05-11 06:43:00          6  2170-05-11      10.3    8  \n",
              "4  2142-09-13 09:23:00          9  2142-09-13      10.2    8  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "morningroutinelab.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn8GfYa_bhiM"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fKw_i14XCTbQ"
      },
      "outputs": [],
      "source": [
        "mrl_sorted = morningroutinelab.sort_values(by=['subject_id', 'hadm_id', 'chartday', 'itemid', 'charthour'])\n",
        "mrl_sampled = mrl_sorted.groupby(['subject_id', 'hadm_id', 'chartday', 'itemid']).first().reset_index()\n",
        "mrl_full = mrl_sampled.pivot(index=['subject_id', 'hadm_id', 'chartday'], columns='itemid', values='valuenum').reset_index()\n",
        "mrl = mrl_full.dropna()\n",
        "mrl = mrl.rename(columns={50882: 'Bic', 50912: 'Crt', 50971: 'Pot', 50983: 'Sod', 51006: 'Ure', 51222: 'Hgb', 51265: 'Plt', 51301: 'Wbc'})\n",
        "columns_to_scale = ['Bic', 'Crt', 'Pot', 'Sod', 'Ure', 'Hgb', 'Plt', 'Wbc']\n",
        "# Initialize MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "# Scale selected columns\n",
        "mrl[columns_to_scale] = scaler.fit_transform(mrl[columns_to_scale])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cZIVhPYtcatV",
        "outputId": "ed24c971-5d16-43ca-9c29-cf1e2d14b06a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>itemid</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>chartday</th>\n",
              "      <th>Bic</th>\n",
              "      <th>Crt</th>\n",
              "      <th>Pot</th>\n",
              "      <th>Sod</th>\n",
              "      <th>Ure</th>\n",
              "      <th>Hgb</th>\n",
              "      <th>Plt</th>\n",
              "      <th>Wbc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10000935</td>\n",
              "      <td>26381316.0</td>\n",
              "      <td>2187-08-25</td>\n",
              "      <td>0.463415</td>\n",
              "      <td>0.019417</td>\n",
              "      <td>0.217949</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.044304</td>\n",
              "      <td>0.254902</td>\n",
              "      <td>0.318553</td>\n",
              "      <td>0.048686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10000980</td>\n",
              "      <td>25242409.0</td>\n",
              "      <td>2191-04-05</td>\n",
              "      <td>0.414634</td>\n",
              "      <td>0.111650</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.594937</td>\n",
              "      <td>0.385621</td>\n",
              "      <td>0.065344</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10001401</td>\n",
              "      <td>21544441.0</td>\n",
              "      <td>2131-06-06</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>0.029126</td>\n",
              "      <td>0.282051</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.107595</td>\n",
              "      <td>0.464052</td>\n",
              "      <td>0.126021</td>\n",
              "      <td>0.029876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10001884</td>\n",
              "      <td>26170293.0</td>\n",
              "      <td>2130-04-17</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>0.033981</td>\n",
              "      <td>0.217949</td>\n",
              "      <td>0.543478</td>\n",
              "      <td>0.056962</td>\n",
              "      <td>0.581699</td>\n",
              "      <td>0.122520</td>\n",
              "      <td>0.015214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10004235</td>\n",
              "      <td>22187210.0</td>\n",
              "      <td>2196-06-21</td>\n",
              "      <td>0.365854</td>\n",
              "      <td>0.058252</td>\n",
              "      <td>0.256410</td>\n",
              "      <td>0.456522</td>\n",
              "      <td>0.056962</td>\n",
              "      <td>0.326797</td>\n",
              "      <td>0.137690</td>\n",
              "      <td>0.037068</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "itemid  subject_id     hadm_id    chartday       Bic       Crt       Pot  \\\n",
              "0         10000935  26381316.0  2187-08-25  0.463415  0.019417  0.217949   \n",
              "1         10000980  25242409.0  2191-04-05  0.414634  0.111650  0.256410   \n",
              "2         10001401  21544441.0  2131-06-06  0.487805  0.029126  0.282051   \n",
              "4         10001884  26170293.0  2130-04-17  0.487805  0.033981  0.217949   \n",
              "6         10004235  22187210.0  2196-06-21  0.365854  0.058252  0.256410   \n",
              "\n",
              "itemid       Sod       Ure       Hgb       Plt       Wbc  \n",
              "0       0.500000  0.044304  0.254902  0.318553  0.048686  \n",
              "1       0.739130  0.594937  0.385621  0.065344  0.015491  \n",
              "2       0.521739  0.107595  0.464052  0.126021  0.029876  \n",
              "4       0.543478  0.056962  0.581699  0.122520  0.015214  \n",
              "6       0.456522  0.056962  0.326797  0.137690  0.037068  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mrl.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MvPEsCMclaF"
      },
      "source": [
        "### Encode Numbers -> Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "ixrIG7jdck5W",
        "outputId": "b9668b24-b101-4844-c0f8-378369191240"
      },
      "outputs": [],
      "source": [
        "def int_to_letters(number):\n",
        "    result = \"\"\n",
        "    while number >= 0:\n",
        "        number, remainder = divmod(number, 26)\n",
        "        result = chr(65 + remainder) + result\n",
        "        if number == 0:\n",
        "            break\n",
        "        number -= 1  # Adjust for 0-based indexing\n",
        "    return result\n",
        "\n",
        "# Generate letters for numbers from 0 to 99\n",
        "letters_mapping = {i: int_to_letters(i) for i in range(101)}\n",
        "def scale_to_letter(value):\n",
        "    return letters_mapping[int(value * 100)]\n",
        "\n",
        "mrl['nstr'] = mrl[columns_to_scale].apply(lambda row: ' '.join(f'{col}{scale_to_letter(val)}' for col, val in zip(columns_to_scale, row)), axis=1)\n",
        "grouped_mrl = mrl.groupby('hadm_id')['nstr'].apply(list).reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Giq7MpMDc1WC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hadm_id</th>\n",
              "      <th>nstr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000235.0</td>\n",
              "      <td>[BicAR CrtU PotY SodAI UreV HgbAE PltB WbcA]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20004357.0</td>\n",
              "      <td>[BicBE CrtD PotAG SodBA UreL HgbAE PltP WbcC]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20005361.0</td>\n",
              "      <td>[BicAU CrtE PotAC SodBP UreL HgbAE PltK WbcB]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20005721.0</td>\n",
              "      <td>[BicAI CrtA PotZ SodAR UreB HgbAG PltR WbcB]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20007831.0</td>\n",
              "      <td>[BicBG CrtE PotAE SodAY UreP HgbZ PltT WbcE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8555</th>\n",
              "      <td>29991539.0</td>\n",
              "      <td>[BicAP CrtI PotV SodBI UreS HgbAI PltN WbcD]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8556</th>\n",
              "      <td>29995410.0</td>\n",
              "      <td>[BicAU CrtD PotV SodAP UreF HgbAJ PltG WbcA]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8557</th>\n",
              "      <td>29997206.0</td>\n",
              "      <td>[BicAR CrtC PotAL SodAY UreC HgbAG PltP WbcD]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8558</th>\n",
              "      <td>29998928.0</td>\n",
              "      <td>[BicAR CrtF PotAG SodAK UreO HgbAV PltS WbcC]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8559</th>\n",
              "      <td>29999596.0</td>\n",
              "      <td>[BicAP CrtE PotAL SodAC UreR HgbAL PltAE WbcE]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8560 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         hadm_id                                            nstr\n",
              "0     20000235.0    [BicAR CrtU PotY SodAI UreV HgbAE PltB WbcA]\n",
              "1     20004357.0   [BicBE CrtD PotAG SodBA UreL HgbAE PltP WbcC]\n",
              "2     20005361.0   [BicAU CrtE PotAC SodBP UreL HgbAE PltK WbcB]\n",
              "3     20005721.0    [BicAI CrtA PotZ SodAR UreB HgbAG PltR WbcB]\n",
              "4     20007831.0    [BicBG CrtE PotAE SodAY UreP HgbZ PltT WbcE]\n",
              "...          ...                                             ...\n",
              "8555  29991539.0    [BicAP CrtI PotV SodBI UreS HgbAI PltN WbcD]\n",
              "8556  29995410.0    [BicAU CrtD PotV SodAP UreF HgbAJ PltG WbcA]\n",
              "8557  29997206.0   [BicAR CrtC PotAL SodAY UreC HgbAG PltP WbcD]\n",
              "8558  29998928.0   [BicAR CrtF PotAG SodAK UreO HgbAV PltS WbcC]\n",
              "8559  29999596.0  [BicAP CrtE PotAL SodAC UreR HgbAL PltAE WbcE]\n",
              "\n",
              "[8560 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grouped_mrl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IREewDITdA_t"
      },
      "source": [
        "### Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Insert special tokens into the list\n",
        "def insert_special_tokens(input_list, special_tokens):\n",
        "    result_list = input_list.copy()\n",
        "    for position, token in special_tokens.items():\n",
        "        result_list.insert(position, token)\n",
        "    return result_list\n",
        "\n",
        "# Create a vocab.txt file\n",
        "def create_vocab_file(vocab_list, vocab_file_path):\n",
        "    with open(vocab_file_path, 'w', encoding='utf-8') as vocab_file:\n",
        "        for token in vocab_list:\n",
        "            vocab_file.write(token + '\\n')\n",
        "\n",
        "# Create a BERT tokenizer\n",
        "def create_bert_tokenizer(vocab_file_path):\n",
        "    tokenizer = BertTokenizer(vocab_file_path, do_lower_case=False)\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_list = mrl['nstr'].str.split(' ').explode().unique().tolist()\n",
        "special_tokens = {0: '[PAD]', 101: '[CLS]', 102: '[SEP]', 103: '[MASK]'}\n",
        "\n",
        "# Insert special tokens into the list\n",
        "modified_vocab = insert_special_tokens(vocab_list, special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a vocab.txt file\n",
        "vocab_file_path = 'vocab.txt'\n",
        "create_vocab_file(modified_vocab, vocab_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a BERT tokenizer\n",
        "tokenizer = create_bert_tokenizer(vocab_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "496"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "LT2H1lgQiOoX"
      },
      "outputs": [],
      "source": [
        "text = grouped_mrl['nstr'].apply(lambda x: ' [SEP] '.join(x)).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_train_test_split(data, train_percent=.8):\n",
        "    # Randomly split data into training and test sets.\n",
        "    np.random.seed(42)\n",
        "    data = np.array(data)\n",
        "    np.random.shuffle(data)\n",
        "    train_size = int(len(data) * train_percent)\n",
        "    train = data[:train_size]\n",
        "    test = data[train_size:]\n",
        "    # Convert to list\n",
        "    train = train.tolist()\n",
        "    test = test.tolist()\n",
        "    return train, test\n",
        "\n",
        "train, test = random_train_test_split(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "sRmj98miCb2F"
      },
      "outputs": [],
      "source": [
        "train_inputs = tokenizer(train, return_tensors='pt', max_length=100, truncation=True, padding='max_length')\n",
        "\n",
        "test_inputs = tokenizer(test, return_tensors='pt', max_length=100, truncation=True, padding='max_length')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzuD84Uqi2Sm"
      },
      "source": [
        "### Dataset Perparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yzceFOWui5qP"
      },
      "outputs": [],
      "source": [
        "train_inputs['labels'] = train_inputs.input_ids.detach().clone()\n",
        "test_inputs['labels'] = test_inputs.input_ids.detach().clone()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "0QVfluICjDO9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_inputs.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMSXaGp1jOoY"
      },
      "source": [
        "Model Masked Language Model (MLM):\n",
        "\n",
        "Pretraining method: The idea is to mask some words (lab values) so the model use the rest of the values to predict the missing values. That way the model will learn the relations between the lab values.\n",
        "\n",
        "To pre-train the model we'll need to mask some values randomly. In this case 20%. We will ignore the tokens CLS (101), SEP (102) and PAD (0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "W2bSMtiYkjU5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD]\n"
          ]
        }
      ],
      "source": [
        "# List of token IDs\n",
        "token_ids = [101, 102, 0]\n",
        "\n",
        "# Decode token IDs to get corresponding values\n",
        "decoded_values = tokenizer.decode(token_ids)\n",
        "\n",
        "print(decoded_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "q6mPeqVTi5tT"
      },
      "outputs": [],
      "source": [
        "def randomly_mask_dataset(inputs, parcentage=0.20, CLS=101, SEP=102, PAD=0):\n",
        "\n",
        "    # create random array of floats with equal dimensions to input_ids tensor\n",
        "    rand = torch.rand(inputs.input_ids.shape)\n",
        "    # Create mask array\n",
        "    mask_arr = (rand < parcentage) * (inputs.input_ids != CLS) * (inputs.input_ids != SEP) * (inputs.input_ids != PAD)\n",
        "\n",
        "    # Take the index of each masked token and replace with the token 103\n",
        "    masked = []\n",
        "\n",
        "    for i in range(inputs.input_ids.shape[0]):\n",
        "        masked.append(torch.flatten(mask_arr[i].nonzero()).tolist())\n",
        "\n",
        "    for i in range(inputs.input_ids.shape[0]):\n",
        "        inputs.input_ids[i, masked[i]] = 103\n",
        "\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Av5tqfETlKYt"
      },
      "outputs": [],
      "source": [
        "MASKING = 0.20\n",
        "\n",
        "train_inputs = randomly_mask_dataset(train_inputs, parcentage=MASKING)\n",
        "test_inputs = randomly_mask_dataset(test_inputs, parcentage=MASKING)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jNorTFbOlfoh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[101,  40, 103,  ...,   0,   0,   0],\n",
              "        [101, 103,  18,  ...,   0,   0,   0],\n",
              "        [101, 160, 103,  ...,   0,   0,   0],\n",
              "        ...,\n",
              "        [101,  51, 103,  ...,   0,   0,   0],\n",
              "        [101, 160,  25,  ...,   0,   0,   0],\n",
              "        [101, 108, 103,  ...,   0,   0,   0]])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_inputs.input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0RSiCWkmJhA"
      },
      "source": [
        "### Dataleader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "RnbC1DqAmJEn"
      },
      "outputs": [],
      "source": [
        "class LabValuesDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings.input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5Sl55pSpmnKm"
      },
      "outputs": [],
      "source": [
        "train_dataset = LabValuesDataset(train_inputs)\n",
        "test_dataset = LabValuesDataset(test_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhE8Gkpni6mY"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "WpQkrtf4m5jJ"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Apple slilicon:\n",
        "device = torch.device('mps') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "x-dCPF3mejwi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForMaskedLM(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(496, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (cls): BertOnlyMLMHead(\n",
              "    (predictions): BertLMPredictionHead(\n",
              "      (transform): BertPredictionHeadTransform(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (transform_act_fn): GELUActivation()\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      )\n",
              "      (decoder): Linear(in_features=768, out_features=496, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "# and move our model over to the selected device\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq1WpCYFnE_N"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "rMiEGMzQm6S1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/davidrestrepo/miniforge3/envs/labrador/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# activate training mode\n",
        "model.train()\n",
        "# initialize optimizer\n",
        "optim = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/428 [00:00<?, ?it/s]/var/folders/4w/k6c16td51cv9ytcmnnvx3mpw0000gn/T/ipykernel_94955/302765012.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
            "Epoch 0: 100%|██████████| 428/428 [45:40<00:00,  6.40s/it, loss=0.235]  \n",
            "Epoch 0 (Eval): 100%|██████████| 107/107 [01:00<00:00,  1.76it/s, loss=0.244]\n",
            "Epoch 1: 100%|██████████| 428/428 [26:04<00:00,  3.65s/it, loss=0.0781]\n",
            "Epoch 1 (Eval): 100%|██████████| 107/107 [01:03<00:00,  1.68it/s, loss=0.0608]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs = 2\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loop = tqdm(train_loader, leave=True)\n",
        "    for batch in train_loop:\n",
        "        optim.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        train_losses.append(loss.item())\n",
        "        train_loop.set_description(f'Epoch {epoch}')\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    test_loop = tqdm(test_loader, leave=True)\n",
        "    for batch in test_loop:\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            test_losses.append(loss.item())\n",
        "            test_loop.set_description(f'Epoch {epoch} (Eval)')\n",
        "            test_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "\n",
        "model.save_pretrained(\"model/\")\n",
        "tokenizer.save_pretrained(\"tokenizer/\")\n",
        "\n",
        "# Plotting\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import BertForMaskedLM, BertTokenizer\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "model = BertForMaskedLM.from_pretrained(\"model/\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"tokenizer/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embeddings(model, tokenizer, texts):\n",
        "\n",
        "    model.eval()\n",
        "    \n",
        "    # Tokenize and convert the input texts to tensors\n",
        "    tokens = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    \n",
        "    # Forward pass to obtain the embeddings\n",
        "    with torch.no_grad():\n",
        "        embeddings = model(**tokens, output_hidden_states=True, return_dict=True)\n",
        "\n",
        "    # Extract the embeddings from the last hidden state\n",
        "    embeddings = np.array(embeddings.hidden_states[-1])\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings Shape: (2, 8, 768)\n",
            "[[[-0.49939942 -0.3252505  -0.30454722 ...  0.1831341   0.15631016\n",
            "    0.0508475 ]\n",
            "  [ 0.8420637   0.7331135   0.06322432 ...  0.7596819  -0.72309816\n",
            "    0.1683993 ]\n",
            "  [ 0.67765754  0.35475954  0.45529342 ...  0.9190105  -0.93369794\n",
            "   -0.20882437]\n",
            "  ...\n",
            "  [ 1.2109077  -0.23138356 -0.23602165 ...  0.7183799  -0.9758155\n",
            "   -0.19742072]\n",
            "  [ 1.7765887   0.2612248   0.46532738 ...  0.59862673 -0.70830154\n",
            "   -0.81637096]\n",
            "  [ 0.369804   -0.38128763 -0.47079998 ...  1.0526273  -0.24447265\n",
            "   -0.499013  ]]\n",
            "\n",
            " [[-0.49586958 -0.35578215 -0.32065305 ...  0.24539039  0.20613106\n",
            "    0.04686604]\n",
            "  [ 0.8305602   0.7563559   0.05792234 ...  0.77873474 -0.75425863\n",
            "    0.15379828]\n",
            "  [ 0.6755165   0.35896558  0.43717715 ...  1.0163783  -0.9384985\n",
            "   -0.26118717]\n",
            "  ...\n",
            "  [ 1.3808904  -0.11981761 -0.27989095 ...  0.5025964  -0.7696203\n",
            "   -0.59993446]\n",
            "  [ 0.39476097 -0.4111559  -0.50136316 ...  1.0499966  -0.22167918\n",
            "   -0.49201792]\n",
            "  [ 0.76907027  0.52228135  1.4269865  ... -0.85269755  0.20391731\n",
            "   -1.4261863 ]]]\n"
          ]
        }
      ],
      "source": [
        "texts_to_embed = [\"This is a sample sentence.\", \"Another example for embeddings.\"]\n",
        "\n",
        "embeddings = get_embeddings(model, tokenizer, texts_to_embed)\n",
        "print(\"Embeddings Shape:\", embeddings.shape)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
